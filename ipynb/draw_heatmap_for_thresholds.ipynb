{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/chendian/PURE')\n",
    "\n",
    "import time\n",
    "import logging\n",
    "from glob import glob\n",
    "from pure_api import PureApi\n",
    "from shared.data_structures import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "task_name = 'msra'\n",
    "# task_name = 'resume'\n",
    "# task_name = 'onto4'\n",
    "test_data = os.path.join(f'../data/{task_name.replace(\"msra\", \"msra_origin\")}/', f'test.with_span_score.json')\n",
    "documents = Dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/chendian/pure_output_dir/msra_origin_spanr_*e*_wn/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0e-0',\n",
       " '5e-3',\n",
       " '1e-2',\n",
       " '5e-2',\n",
       " '1e-1',\n",
       " '2e-1',\n",
       " '3e-1',\n",
       " '4e-1',\n",
       " '5e-1',\n",
       " '6e-1',\n",
       " '7e-1',\n",
       " '8e-1',\n",
       " '9e-1',\n",
       " '1e-0']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model candidates\n",
    "model_dir = '/data/chendian/pure_output_dir'\n",
    "# model_dir = '../output_dir'\n",
    "boundary_only_mode = 'span'\n",
    "span_filter_method = 'rate'\n",
    "file_name_pattern = f'{model_dir}/{task_name.replace(\"msra\", \"msra_origin\")}_{boundary_only_mode}{span_filter_method[0]}_*e*_wn/'\n",
    "print(file_name_pattern)\n",
    "thres_case = [_p.split(\"_\")[-2] for _p in glob(file_name_pattern)]\n",
    "threshold_case = sorted(thres_case, key=lambda x: float(x))\n",
    "# del threshold_case[1:4]\n",
    "threshold_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv ../output_dir/msra_origin_spanf_*_wn /data/chendian/pure_output_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/10/2021 17:25:44 - INFO - transformers.tokenization_utils_base - Model name '/data/chendian/pure_output_dir/msra_origin_spanr_5e-1_wn//' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '/data/chendian/pure_output_dir/msra_origin_spanr_5e-1_wn//' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/10/2021 17:25:44 - INFO - transformers.tokenization_utils_base - Didn't find file /data/chendian/pure_output_dir/msra_origin_spanr_5e-1_wn//added_tokens.json. We won't load it.\n",
      "11/10/2021 17:25:44 - INFO - transformers.tokenization_utils_base - Didn't find file /data/chendian/pure_output_dir/msra_origin_spanr_5e-1_wn//tokenizer.json. We won't load it.\n",
      "11/10/2021 17:25:44 - INFO - transformers.tokenization_utils_base - loading file /data/chendian/pure_output_dir/msra_origin_spanr_5e-1_wn//vocab.txt\n",
      "11/10/2021 17:25:44 - INFO - transformers.tokenization_utils_base - loading file None\n",
      "11/10/2021 17:25:44 - INFO - transformers.tokenization_utils_base - loading file /data/chendian/pure_output_dir/msra_origin_spanr_5e-1_wn//special_tokens_map.json\n",
      "11/10/2021 17:25:44 - INFO - transformers.tokenization_utils_base - loading file /data/chendian/pure_output_dir/msra_origin_spanr_5e-1_wn//tokenizer_config.json\n",
      "11/10/2021 17:25:44 - INFO - transformers.tokenization_utils_base - loading file None\n",
      "11/10/2021 17:25:44 - INFO - transformers.configuration_utils - loading configuration file /data/chendian/pure_output_dir/msra_origin_spanr_5e-1_wn//config.json\n",
      "11/10/2021 17:25:44 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForEntity\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "11/10/2021 17:25:44 - INFO - transformers.modeling_utils - loading weights file /data/chendian/pure_output_dir/msra_origin_spanr_5e-1_wn//pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take ce as loss function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/10/2021 17:25:48 - INFO - transformers.modeling_utils - All model checkpoint weights were used when initializing BertForEntity.\n",
      "\n",
      "11/10/2021 17:25:48 - INFO - transformers.modeling_utils - All the weights of BertForEntity were initialized from the model checkpoint at /data/chendian/pure_output_dir/msra_origin_spanr_5e-1_wn//.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForEntity for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 144.63 seconds.\n",
      "cost 181.19 seconds.\n",
      "cost 206.13 seconds.\n",
      "cost 238.12 seconds.\n",
      "cost 280.71 seconds.\n",
      "cost 407.69 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict on different models with different threshold\n",
    "rec = {}\n",
    "logger = logging.getLogger('root')\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "\n",
    "for boundary_only_mode in ['span']:  # 'bin', 'bdy', \n",
    "    cur_args = {\n",
    "        'task': task_name,\n",
    "        'max_span_length': 40 if task_name == 'findoc' else 25,\n",
    "        'boundary_token': 'both',\n",
    "        'boundary_det_filter_method': 'max',\n",
    "        'boundary_only_mode': f\"{boundary_only_mode}_score\",\n",
    "        'span_filter_method': f\"{span_filter_method}\",\n",
    "        'eval_batch_size': 16,\n",
    "    }\n",
    "\n",
    "    # for trn_threshold in threshold_case:\n",
    "    for trn_threshold in ['5e-1']:\n",
    "        load_model_dir = f'{model_dir}/{task_name.replace(\"msra\", \"msra_origin\")}_{boundary_only_mode}{span_filter_method[0]}_{str(trn_threshold)}_wn/'\n",
    "        # for load_model_dir in glob(f'{model_dir}/{task_name}_{boundary_only_mode}f_*_wn/'):\n",
    "        cur_args.update({\n",
    "            \"boundary_det_threshold\": float(trn_threshold),\n",
    "            'span_filter_method': f\"{span_filter_method}\",\n",
    "        })\n",
    "        pa = PureApi(args=cur_args, \n",
    "                     load_model_dir=load_model_dir)\n",
    "        for phase in ['test']:  # 'train', 'dev', \n",
    "            st = time.time()\n",
    "            for tst_threshold in ['f_0e-0', 'f_5e-1', 'f_1e-0']:  # thres\n",
    "                if (trn_threshold, tst_threshold) in rec:\n",
    "                    continue\n",
    "                pa.args.update({\n",
    "                    \"boundary_det_threshold\": float(tst_threshold.split('_')[1]),\n",
    "                    'span_filter_method': 'thres',\n",
    "                })\n",
    "                p, r, f1 = pa.evaluate(documents=documents)\n",
    "                rec[(trn_threshold, tst_threshold)] = (p, r, f1)\n",
    "                print(\"cost {:.2f} seconds.\".format(time.time()-st))\n",
    "            for tst_threshold in ['r_1e-1', 'r_2e-1', 'r_5e-1', 'r_1e-0']:  # rate\n",
    "                if (trn_threshold, tst_threshold) in rec:\n",
    "                    continue\n",
    "                pa.args.update({\n",
    "                    \"boundary_det_threshold\": float(tst_threshold.split('_')[1]),\n",
    "                    'span_filter_method': 'rate',\n",
    "                })\n",
    "                p, r, f1 = pa.evaluate(documents=documents)\n",
    "                rec[(trn_threshold, tst_threshold)] = (p, r, f1)\n",
    "                print(\"cost {:.2f} seconds.\".format(time.time()-st))\n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the prediction results\n",
    "import pickle\n",
    "# pickle.dump(rec, open(f'../data/filtering_methods/heatmap_on_models_with_{span_filter_method}_{task_name}_211110.pkl', 'wb'))\n",
    "pickle.dump(rec, open(f'../data/filtering_methods/model_with_{span_filter_method}_{task_name}_compare_211110.pkl', 'wb'))\n",
    "# rec = pickle.load(open(f'../data/heatmap_on_models_with_rate_{task_name}_211022.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heatmap_on_models_with_counts_onto4_211109.pkl\n",
      "heatmap_on_models_with_rate_msra_211022.pkl\n",
      "heatmap_on_models_with_rate_msra_211104.pkl\n",
      "heatmap_on_models_with_rate_onto4_211109.pkl\n",
      "heatmap_on_models_with_rate_resume_211104.pkl\n",
      "heatmap_on_models_with_span_filtering_211003.pkl\n",
      "heatmap_on_models_with_thres_msra_211023.pkl\n",
      "heatmap_on_models_with_thres_on_0e-0_211020.pkl\n",
      "heatmap_on_models_with_thres_on_0e-0_msra_211020.pkl\n",
      "heatmap_on_models_with_thres_on_0e-0_onto4_211020.pkl\n",
      "heatmap_on_models_with_thres_on_0e-0_resume_211020.pkl\n",
      "heatmap_on_models_with_thres_on_5e-1_211020.pkl\n",
      "model_with_rate_msra_compare_211110.pkl\n",
      "model_with_rate_onto4_compare_211110.pkl\n",
      "model_with_rate_resume_compare_211110.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/filtering_methods/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onto4 Dataset:\n",
      "\n",
      "\t\t  TakeAll \t\t\t Ours(20%) \t\t\t Ours(10%) \t\t\t Pipeline\n",
      "5e-1\t83.31/80.01/81.63\t5e-1\t83.31/80.01/81.63\t5e-1\t83.30/80.00/81.62\t5e-1\t85.39/77.58/81.30\t\n"
     ]
    }
   ],
   "source": [
    "# show the heatmap \n",
    "print(\"Onto4 Dataset:\\n\") \n",
    "print('\\t\\t  TakeAll \\t\\t Ours(20%) \\t\\t Ours(10%) \\t\\t Pipeline') \n",
    "for trn_threshold in ['5e-1']: \n",
    "    print(f\"{trn_threshold}\", end='\\t')\n",
    "    for tst_threshold in ['f_0e-0', 'r_2e-1', 'r_1e-1', 'f_5e-1']: \n",
    "        p, r, f = rec[(trn_threshold, tst_threshold)] \n",
    "        p, r, f = 100.*p, 100.*r, 100.*f \n",
    "        # print(f'{p:.2f}/{r:.2f}/{f:.2f}', end='\\t') \n",
    "        print(f'{p:.2f}/{r:.2f}/{f:.2f}', end='\\t') \n",
    "    print(\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Dataset:\n",
      "\n",
      "\t\t  TakeAll \t\t\t Ours(20%) \t\t\t Ours(10%) \t\t\t Pipeline\n",
      "5e-1\t95.96/96.07/96.01\t5e-1\t95.95/95.89/95.92\t5e-1\t95.92/95.15/95.53\t5e-1\t96.70/95.28/95.98\t\n"
     ]
    }
   ],
   "source": [
    "# show the heatmap \n",
    "print(\"Resume Dataset:\\n\") \n",
    "print('\\t\\t  TakeAll \\t\\t Ours(20%) \\t\\t Ours(10%) \\t\\t Pipeline') \n",
    "for trn_threshold in ['5e-1']: \n",
    "    print(f\"{trn_threshold}\", end='\\t')\n",
    "    for tst_threshold in ['f_0e-0', 'r_2e-1', 'r_1e-1', 'f_5e-1']: \n",
    "        p, r, f = rec[(trn_threshold, tst_threshold)] \n",
    "        p, r, f = 100.*p, 100.*r, 100.*f \n",
    "        # print(f'{p:.2f}/{r:.2f}/{f:.2f}', end='\\t') \n",
    "        print(f'{p:.2f}/{r:.2f}/{f:.2f}', end='\\t') \n",
    "    print(\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSRA Dataset:\n",
      "\n",
      "\t\t  TakeAll \t\t Ours(20%) \t\t Ours(10%) \t\t Pipeline\n",
      "5e-1\t96.05/95.75/95.90\t96.05/95.75/95.90\t96.06/95.75/95.91\t97.25/94.20/95.70\t\n"
     ]
    }
   ],
   "source": [
    "# show the heatmap \n",
    "print(\"MSRA Dataset:\\n\") \n",
    "print('\\t\\t  TakeAll \\t\\t Ours(50%) \\t\\t Ours(20%) \\t\\t Ours(10%) \\t\\t Pipeline') \n",
    "for trn_threshold in ['5e-1']: \n",
    "    print(f\"{trn_threshold}\", end='\\t')\n",
    "    for tst_threshold in ['f_0e-0', 'r_5e-1', 'r_2e-1', 'r_1e-1', 'f_5e-1']: \n",
    "        p, r, f = rec[(trn_threshold, tst_threshold)] \n",
    "        p, r, f = 100.*p, 100.*r, 100.*f \n",
    "        # print(f'{p:.2f}/{r:.2f}/{f:.2f}', end='\\t') \n",
    "        print(f'{p:.2f}/{r:.2f}/{f:.2f}', end='\\t') \n",
    "    print(\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(threshold_case)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab478a5a1ebe8d3272f11e140b1127aeaad7a84ba8242059d9ceda920cc73b22"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
